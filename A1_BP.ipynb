{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Pandas library for reading the dataset file**"
      ],
      "metadata": {
        "id": "-Mzr2EhAZrI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "DwficKhTZO5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "turbine_data = pd.read_csv('A1-turbine.txt', sep='\\t', header=None)\n",
        "synthetic_data = pd.read_csv('A1-synthetic.txt', sep='\\t', header=None)\n",
        "\n",
        "# Display the first few rows of the datasets\n",
        "print('Turbine Data:')\n",
        "print(turbine_data.head())\n",
        "print('\\nSynthetic Data:')\n",
        "print(synthetic_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYJXJ00nZO8t",
        "outputId": "30c631e6-7b7d-4cd0-b67e-878cdf3bc3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbine Data:\n",
            "                        0       1       2      3        4  \\\n",
            "0  #height_over_sea_level    fall     net   fall     flow   \n",
            "1                  624.00  89.160  89.765  3.500  2512.85   \n",
            "2                  628.00  93.160  93.765  3.500  2583.79   \n",
            "3                  602.00  67.840  66.415  6.500  3748.77   \n",
            "4                  599.00  64.840  63.415  6.500  3520.65   \n",
            "\n",
            "                                  5  \n",
            "0  power_of_hydroelectrical_turbine  \n",
            "1                               NaN  \n",
            "2                               NaN  \n",
            "3                               NaN  \n",
            "4                               NaN  \n",
            "\n",
            "Synthetic Data:\n",
            "              0            1            2            3            4  \\\n",
            "0           #v1           v2           v3           v4           v5   \n",
            "1   37.34411029  10.54215603  0.969185269  3.568534461  96.79873311   \n",
            "2   4.089848542  11.89430069  0.467774583   1.27904375  100.1493827   \n",
            "3  -32.33343934  10.96863118  0.238486094  1.410744921  100.6420745   \n",
            "4  -45.63297745   11.5096061   0.92493831  3.404068612  105.9630162   \n",
            "\n",
            "             5            6   7            8            9  \n",
            "0           v6           v7  v8           v9            z  \n",
            "1  3.429026069  75.81019559   0   20.0024589  11.80536855  \n",
            "2  3.190072621  76.42309484   0  12.70262834  5.125025474  \n",
            "3  3.093933998  78.75872686   1  10.72384766  3.218552513  \n",
            "4   2.88426914  83.02775038   0  19.94659322  12.95509245  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-Processing**\n",
        "Now we need to check the dataset,\n",
        "Is there is any missing value?"
      ],
      "metadata": {
        "id": "h8eTgs96anUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_missing_values(data):\n",
        "    missing_values = data.isnull().sum()\n",
        "    total_missing_values = missing_values.sum()\n",
        "    return total_missing_values > 0, total_missing_values"
      ],
      "metadata": {
        "id": "tZ9Ne8LuZ6ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the turbine data\n",
        "has_missing_values, total_missing_values = check_missing_values(turbine_data)\n",
        "print(f'Turbine Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')\n",
        "\n",
        "# Check for missing values in the synthetic data\n",
        "has_missing_values, total_missing_values = check_missing_values(synthetic_data)\n",
        "print(f'Synthetic Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KryyMqOZpVF",
        "outputId": "08fb051b-6fed-4c3c-852b-06017cf889d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbine Data: Has missing values? True, Total missing values: 451\n",
            "Synthetic Data: Has missing values? False, Total missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing values from the turbine data\n",
        "turbine_data = turbine_data.dropna()\n",
        "\n",
        "# Remove rows with missing values from the synthetic data\n",
        "synthetic_data = synthetic_data.dropna()\n",
        "\n",
        "# Check again for missing values in the turbine data\n",
        "has_missing_values, total_missing_values = check_missing_values(turbine_data)\n",
        "print(f'Turbine Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')\n",
        "\n",
        "# Check again for missing values in the synthetic data\n",
        "has_missing_values, total_missing_values = check_missing_values(synthetic_data)\n",
        "print(f'Synthetic Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6L0YHi5Z-uJ",
        "outputId": "09b29b58-55b9-4a1c-f610-da4604ed122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbine Data: Has missing values? False, Total missing values: 0\n",
            "Synthetic Data: Has missing values? False, Total missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def normalize_data(data):\n",
        "    scaler = MinMaxScaler()\n",
        "    normalized_data = scaler.fit_transform(data)\n",
        "    return normalized_data"
      ],
      "metadata": {
        "id": "jR07FqoibvAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets, skipping non-numeric rows\n",
        "turbine_data = pd.read_csv('A1-turbine.txt', sep='\\t', header=None, comment='#')\n",
        "synthetic_data = pd.read_csv('A1-synthetic.txt', sep='\\t', header=None, comment='#')\n",
        "\n",
        "# Check for missing values in the turbine data\n",
        "has_missing_values, total_missing_values = check_missing_values(turbine_data)\n",
        "print(f'Turbine Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')\n",
        "\n",
        "# Check for missing values in the synthetic data\n",
        "has_missing_values, total_missing_values = check_missing_values(synthetic_data)\n",
        "print(f'Synthetic Data: Has missing values? {has_missing_values}, Total missing values: {total_missing_values}')\n",
        "\n",
        "# Normalize the turbine data\n",
        "turbine_data_normalized = normalize_data(turbine_data)\n",
        "\n",
        "# Normalize the synthetic data\n",
        "synthetic_data_normalized = normalize_data(synthetic_data)\n",
        "\n",
        "# Display the first few rows of the normalized datasets\n",
        "print('Normalized Turbine Data:')\n",
        "print(turbine_data_normalized[:5])\n",
        "print('\\nNormalized Synthetic Data:')\n",
        "print(synthetic_data_normalized[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZlssukubFH9",
        "outputId": "e95c752e-4f93-4ede-9e42-3511f241e1bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turbine Data: Has missing values? False, Total missing values: 0\n",
            "Synthetic Data: Has missing values? False, Total missing values: 0\n",
            "Normalized Turbine Data:\n",
            "[[0.84615385 0.82115677 0.84875597 0.08333333 0.14995677]\n",
            " [0.94871795 0.92262811 0.94680721 0.08333333 0.1626559 ]\n",
            " [0.28205128 0.28031456 0.27638191 0.58333333 0.37120158]\n",
            " [0.20512821 0.20421106 0.20284349 0.58333333 0.33036531]\n",
            " [1.         0.96144089 0.94129182 0.83333333 0.89482493]]\n",
            "\n",
            "Normalized Synthetic Data:\n",
            "[[0.87433469 0.2711503  0.96944516 0.85612733 0.37474332 0.89434557\n",
            "  0.41492498 0.         0.82977202 0.74661996]\n",
            " [0.54123414 0.94753193 0.4678239  0.09229697 0.48250717 0.74746761\n",
            "  0.43410926 0.         0.21808604 0.35066199]\n",
            " [0.17639016 0.48448543 0.23843911 0.13623572 0.49835317 0.6883739\n",
            "  0.50721657 1.         0.05227501 0.23766133]\n",
            " [0.04317164 0.75509664 0.92517962 0.80125748 0.66948571 0.55949881\n",
            "  0.64084071 0.         0.82509078 0.81476651]\n",
            " [0.08413609 0.05856788 0.31516497 0.0059135  0.39316222 0.51742508\n",
            "  0.45825376 0.         0.08421548 0.16063972]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet:\n",
        "    def __init__(self, layers):\n",
        "        self.L = len(layers)\n",
        "        self.n = layers.copy()\n",
        "\n",
        "        self.xi = []\n",
        "        for lay in range(self.L):\n",
        "            self.xi.append(np.zeros(layers[lay]))\n",
        "\n",
        "        self.w = []\n",
        "        self.w.append(np.zeros((1, 1)))\n",
        "        for lay in range(1, self.L):\n",
        "            self.w.append(np.zeros((layers[lay], layers[lay - 1])))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def forward_pass(self, x):\n",
        "        self.xi[0] = x\n",
        "        for lay in range(1, self.L):\n",
        "            self.xi[lay] = self.sigmoid(np.dot(self.w[lay], self.xi[lay - 1]))\n",
        "        return self.xi[-1]\n",
        "\n",
        "    def backward_pass(self, y):\n",
        "        self.delta = [0] * self.L\n",
        "        self.delta[-1] = (self.xi[-1] - y) * self.xi[-1] * (1 - self.xi[-1])\n",
        "        for lay in range(self.L - 2, -1, -1):\n",
        "            self.delta[lay] = np.dot(self.w[lay + 1].T, self.delta[lay + 1]) * self.xi[lay] * (1 - self.xi[lay])\n",
        "        return self.delta\n",
        "\n",
        "    def update_weights(self, lr):\n",
        "        for lay in range(self.L - 1, 0, -1):\n",
        "            self.w[lay] -= lr * np.dot(self.delta[lay].reshape(-1, 1), self.xi[lay - 1].reshape(1, -1))\n",
        "        return self.w\n",
        "\n",
        "    def train(self, X, y, epochs, lr):\n",
        "        history = []\n",
        "        for epoch in range(epochs):\n",
        "            for i in range(X.shape[0]):\n",
        "                output = self.forward_pass(X[i].reshape(-1, 1))\n",
        "                self.backward_pass(y[i])\n",
        "                self.update_weights(lr)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean(np.square(y - self.forward_pass(X.T)))\n",
        "                history.append(loss)\n",
        "                print(f'Epoch {epoch}: loss {loss}')\n",
        "        return history"
      ],
      "metadata": {
        "id": "DJcfhYJ4oNp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, sep='\\t', header=None)\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].values\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "sk6nr-nloeJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = pd.read_csv(file_path, sep='\\t', header=None, skiprows=1)\n",
        "    X = data.iloc[:, :-1].values\n",
        "    y = data.iloc[:, -1].values\n",
        "    return X, y\n",
        "\n",
        "X_turbine, y_turbine = load_data('A1-turbine.txt')\n",
        "X_synthetic, y_synthetic = load_data('A1-synthetic.txt')\n",
        "\n",
        "X_train_turbine, X_test_turbine, y_train_turbine, y_test_turbine = preprocess_data(X_turbine, y_turbine)\n",
        "X_train_synthetic, X_test_synthetic, y_train_synthetic, y_test_synthetic = preprocess_data(X_synthetic, y_synthetic)"
      ],
      "metadata": {
        "id": "CgCOGf9koaVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "nn_turbine = NeuralNet([4, 5, 1])\n",
        "nn_synthetic = NeuralNet([9, 5, 1])\n",
        "\n",
        "history_turbine = nn_turbine.train(X_train_turbine, y_train_turbine, epochs=1000, lr=0.1)\n",
        "history_synthetic = nn_synthetic.train(X_train_synthetic, y_train_synthetic, epochs=1000, lr=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDuT10FBoUS7",
        "outputId": "1dc9b5b9-adca-470d-d327-2e679af4daa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss 16285916.015195556\n",
            "Epoch 100: loss 16285916.015195556\n",
            "Epoch 200: loss 16285916.015195556\n",
            "Epoch 300: loss 16285916.015195556\n",
            "Epoch 400: loss 16285916.015195556\n",
            "Epoch 500: loss 16285916.015195556\n",
            "Epoch 600: loss 16285916.015195556\n",
            "Epoch 700: loss 16285916.015195556\n",
            "Epoch 800: loss 16285916.015195556\n",
            "Epoch 900: loss 16285916.015195556\n",
            "Epoch 0: loss 42.222145971922245\n",
            "Epoch 100: loss 42.21538865592272\n",
            "Epoch 200: loss 42.215360353716676\n",
            "Epoch 300: loss 42.21535096987551\n",
            "Epoch 400: loss 42.21534629739921\n",
            "Epoch 500: loss 42.21534350295044\n",
            "Epoch 600: loss 42.2153416448421\n",
            "Epoch 700: loss 42.21534032051051\n",
            "Epoch 800: loss 42.215339329110094\n",
            "Epoch 900: loss 42.21533855927064\n"
          ]
        }
      ]
    }
  ]
}