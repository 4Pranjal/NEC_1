{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "noteable-chatgpt": {
      "create_notebook": {
        "openai_conversation_id": "93e68c77-1398-5079-a506-a392d8e0aff3",
        "openai_ephemeral_user_id": "49f0501a-cc7f-510b-a2ff-29410cedbd12",
        "openai_subdivision1_iso_code": "ES-CT"
      }
    },
    "noteable": {
      "last_transaction_id": "81573fc6-4f51-479d-a000-705df520e83b"
    },
    "selected_hardware_size": "small"
  },
  "cells": [
    {
      "id": "f90cc066-97b4-43bb-a2d4-dcacb02e9ca9",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "cb4d77ba-0cac-46c0-aaa0-9283f29250b5"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:46:42.446125+00:00",
          "start_time": "2023-06-19T17:46:41.826919+00:00"
        }
      },
      "execution_count": null,
      "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\n\n# Load the datasets\nturbine_data = pd.read_csv('A1-turbine.txt', sep='\\t', header=None, comment='#')\nsynthetic_data = pd.read_csv('A1-synthetic.txt', sep='\\t', header=None, comment='#')\n\n# Split the turbine data into input data and target output\nturbine_data_input = turbine_data.iloc[:, 1:].values\nturbine_data_output = turbine_data.iloc[:, 0].values\n\n# Split the synthetic data into input data and target output\nsynthetic_data_input = synthetic_data.iloc[:, 1:].values\nsynthetic_data_output = synthetic_data.iloc[:, 0].values\n\n# Display the first few rows of the datasets\nprint('Turbine Data:')\nprint(turbine_data.head())\nprint('\\nSynthetic Data:')\nprint(synthetic_data.head())",
      "outputs": []
    },
    {
      "id": "0a653ede-ee8d-48f2-b492-aec28f9c37fa",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "b2af0e49-db0b-40bd-9fff-326bc466f7f1"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:47:31.012790+00:00",
          "start_time": "2023-06-19T17:47:30.446329+00:00"
        }
      },
      "execution_count": null,
      "source": "# Define a function to calculate the Mean Absolute Percentage Error (MAPE)\ndef calculate_mape(y_true, y_pred):\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n# Train an MLR model on the turbine data\nmlr_turbine = LinearRegression()\nmlr_turbine.fit(turbine_data_input_train, turbine_data_output_train)\n\n# Make predictions on the turbine test set\nturbine_predictions = mlr_turbine.predict(turbine_data_input_test)\n\n# Calculate the MAPE for the turbine predictions\nturbine_mape = calculate_mape(turbine_data_output_test, turbine_predictions)\nprint('Turbine Data: MAPE =', turbine_mape)\n\n# Train an MLR model on the synthetic data\nmlr_synthetic = LinearRegression()\nmlr_synthetic.fit(synthetic_data_input_train, synthetic_data_output_train)\n\n# Make predictions on the synthetic test set\nsynthetic_predictions = mlr_synthetic.predict(synthetic_data_input_test)\n\n# Calculate the MAPE for the synthetic predictions\nsynthetic_mape = calculate_mape(synthetic_data_output_test, synthetic_predictions)\nprint('Synthetic Data: MAPE =', synthetic_mape)",
      "outputs": []
    },
    {
      "id": "75cc2d26-32b0-44be-acb1-d0f3c35a4d97",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "0040d91c-b3d8-4a46-aa40-6ce398ee9cbc"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:48:12.781242+00:00",
          "start_time": "2023-06-19T17:48:12.622313+00:00"
        }
      },
      "execution_count": null,
      "source": "# Split the turbine data into training and test sets\nturbine_data_input_train, turbine_data_input_test, turbine_data_output_train, turbine_data_output_test = train_test_split(turbine_data_input, turbine_data_output, test_size=0.2, random_state=42)\n\n# Split the synthetic data into training and test sets\nsynthetic_data_input_train, synthetic_data_input_test, synthetic_data_output_train, synthetic_data_output_test = train_test_split(synthetic_data_input, synthetic_data_output, test_size=0.2, random_state=42)\n\n# Display the shapes of the training and test sets\nprint('Turbine Data: Training set shape:', turbine_data_input_train.shape, 'Test set shape:', turbine_data_input_test.shape)\nprint('Synthetic Data: Training set shape:', synthetic_data_input_train.shape, 'Test set shape:', synthetic_data_input_test.shape)",
      "outputs": []
    },
    {
      "id": "c8d15b70-7374-4b49-80d3-100e3c59e682",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "e35e001e-44cc-4122-881a-ff854937161c"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:49:17.124236+00:00",
          "start_time": "2023-06-19T17:49:16.961558+00:00"
        }
      },
      "execution_count": null,
      "source": "# Train an MLR model on the turbine data\nmlr_turbine = LinearRegression()\nmlr_turbine.fit(turbine_data_input_train, turbine_data_output_train)\n\n# Make predictions on the turbine test set\nturbine_predictions = mlr_turbine.predict(turbine_data_input_test)\n\n# Calculate the MAPE for the turbine predictions\nturbine_mape = calculate_mape(turbine_data_output_test, turbine_predictions)\nprint('Turbine Data: MAPE =', turbine_mape)\n\n# Train an MLR model on the synthetic data\nmlr_synthetic = LinearRegression()\nmlr_synthetic.fit(synthetic_data_input_train, synthetic_data_output_train)\n\n# Make predictions on the synthetic test set\nsynthetic_predictions = mlr_synthetic.predict(synthetic_data_input_test)\n\n# Calculate the MAPE for the synthetic predictions\nsynthetic_mape = calculate_mape(synthetic_data_output_test, synthetic_predictions)\nprint('Synthetic Data: MAPE =', synthetic_mape)",
      "outputs": []
    },
    {
      "id": "4de32f5d-ad1d-4a23-951e-3dda89d85534",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "f1ee73e4-6413-4e9b-88c2-a87374aabe35"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:50:06.630286+00:00",
          "start_time": "2023-06-19T17:50:05.447991+00:00"
        }
      },
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt\n\n# Create a scatter plot for the turbine data\nplt.figure(figsize=(10, 5))\nplt.scatter(turbine_data_output_test, turbine_predictions)\nplt.xlabel('Real Values')\nplt.ylabel('Predicted Values')\nplt.title('Turbine Data: Real vs Predicted Values')\nplt.grid(True)\nplt.show()\n\n# Create a scatter plot for the synthetic data\nplt.figure(figsize=(10, 5))\nplt.scatter(synthetic_data_output_test, synthetic_predictions)\nplt.xlabel('Real Values')\nplt.ylabel('Predicted Values')\nplt.title('Synthetic Data: Real vs Predicted Values')\nplt.grid(True)\nplt.show()",
      "outputs": []
    },
    {
      "id": "c07cad91-25be-4efa-8205-773063eb500b",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "200fab10-edc6-44f0-a110-137fbba04504"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:51:52.209879+00:00",
          "start_time": "2023-06-19T17:51:51.948174+00:00"
        },
        "datalink": {
          "2389d9e0-ddae-43ec-ab16-2479c58936e8": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 14,
              "orig_num_rows": 5,
              "orig_size_bytes": 600,
              "truncated_num_cols": 14,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 600,
              "truncated_string_columns": []
            },
            "display_id": "2389d9e0-ddae-43ec-ab16-2479c58936e8",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-19T17:51:52.051719",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_1916309b15b64881b52d5c9bf05e959e"
          }
        }
      },
      "execution_count": null,
      "source": "from sklearn.datasets import load_boston\n\n# Load the Boston Housing Dataset\nboston = load_boston()\nboston_data = pd.DataFrame(boston.data, columns=boston.feature_names)\nboston_data['MEDV'] = boston.target\n\n# Display the first few rows of the dataset\nboston_data.head()",
      "outputs": []
    },
    {
      "id": "f87c6301-e2bc-4289-aea0-03b6c27f6ed8",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "0580a8e2-a6d3-4547-a079-b0ed78139edd"
        },
        "ExecuteTime": {
          "end_time": "2023-06-19T17:53:06.207458+00:00",
          "start_time": "2023-06-19T17:53:06.048605+00:00"
        }
      },
      "execution_count": null,
      "source": "# Split the dataset into input data and target output\nboston_data_input = boston_data.iloc[:, :-1].values\nboston_data_output = boston_data.iloc[:, -1].values\n\n# Split the dataset into training and test sets\nboston_data_input_train, boston_data_input_test, boston_data_output_train, boston_data_output_test = train_test_split(boston_data_input, boston_data_output, test_size=0.2, random_state=42)\n\n# Display the shapes of the training and test sets\nprint('Boston Housing Data: Training set shape:', boston_data_input_train.shape, 'Test set shape:', boston_data_input_test.shape)",
      "outputs": []
    },
    {
      "id": "8aea6f65-1b82-4123-b019-bc775684c00a",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4cc71ad0-d479-4741-b959-0e629ae32744"
        },
        "ExecuteTime": {
          "end_time": "2023-06-20T07:47:33.609910+00:00",
          "start_time": "2023-06-20T07:47:32.930371+00:00"
        },
        "datalink": {
          "5dbd7fd9-cfee-4754-a01a-1a08e44264a0": {
            "applied_filters": [],
            "dataframe_info": {
              "default_index_used": true,
              "orig_num_cols": 14,
              "orig_num_rows": 5,
              "orig_size_bytes": 600,
              "truncated_num_cols": 14,
              "truncated_num_rows": 5,
              "truncated_size_bytes": 600,
              "truncated_string_columns": []
            },
            "display_id": "5dbd7fd9-cfee-4754-a01a-1a08e44264a0",
            "dx_settings": {
              "ALLOW_NOTEABLE_ATTRS": true,
              "COLUMN_SAMPLING_METHOD": "outer",
              "DB_LOCATION": ":memory:",
              "DEV_MODE": false,
              "DISPLAY_MAX_COLUMNS": 100,
              "DISPLAY_MAX_ROWS": 50000,
              "DISPLAY_MODE": "simple",
              "ENABLE_ASSIGNMENT": true,
              "ENABLE_DATALINK": true,
              "FLATTEN_COLUMN_VALUES": true,
              "FLATTEN_INDEX_VALUES": false,
              "GENERATE_DEX_METADATA": false,
              "HTML_TABLE_SCHEMA": false,
              "LOG_LEVEL": 30,
              "MAX_RENDER_SIZE_BYTES": 104857600,
              "MAX_STRING_LENGTH": 250,
              "NUM_PAST_SAMPLES_TRACKED": 3,
              "RANDOM_STATE": 12648430,
              "RESET_INDEX_VALUES": false,
              "ROW_SAMPLING_METHOD": "random",
              "SAMPLING_FACTOR": 0.1,
              "SAMPLING_METHOD": "random",
              "STRINGIFY_COLUMN_VALUES": true,
              "STRINGIFY_INDEX_VALUES": false
            },
            "sample_history": [],
            "sampling_time": "2023-06-20T07:47:33.451111",
            "user_variable_name": null,
            "variable_name": "unk_dataframe_503355d76174432b9d7cbcda8207838e"
          }
        }
      },
      "execution_count": null,
      "source": "from sklearn.datasets import load_boston\n\n# Load the Boston Housing Dataset\nboston = load_boston()\nboston_data = pd.DataFrame(boston.data, columns=boston.feature_names)\nboston_data['MEDV'] = boston.target\n\n# Display the first few rows of the dataset\nboston_data.head()",
      "outputs": []
    },
    {
      "id": "c7dbe377-2149-4699-b687-6a449d6e084a",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "eb2c46b5-7e2c-421e-9791-881369bc8f0c"
        },
        "ExecuteTime": {
          "end_time": "2023-06-20T07:49:21.692404+00:00",
          "start_time": "2023-06-20T07:49:21.514398+00:00"
        }
      },
      "execution_count": null,
      "source": "from sklearn.model_selection import train_test_split\n\n# Split the Boston Housing data into input data and target output\nboston_data_input = boston_data.drop('MEDV', axis=1).values\nboston_data_output = boston_data['MEDV'].values\n\n# Split the Boston Housing data into training and test sets\nboston_data_input_train, boston_data_input_test, boston_data_output_train, boston_data_output_test = train_test_split(boston_data_input, boston_data_output, test_size=0.2, random_state=42)\n\n# Display the shapes of the training and test sets\nprint('Boston Housing Data: Training set shape:', boston_data_input_train.shape, 'Test set shape:', boston_data_input_test.shape)",
      "outputs": []
    },
    {
      "id": "efe3ff08-17ba-468d-815c-299a040c4015",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "4b4d206b-7e50-472b-9f4d-52559935c2d7"
        },
        "ExecuteTime": {
          "end_time": "2023-06-20T08:22:20.582980+00:00",
          "start_time": "2023-06-20T08:22:20.424297+00:00"
        }
      },
      "execution_count": null,
      "source": "from sklearn.linear_model import LinearRegression\n\n# Train an MLR model on the Boston Housing data\nmlr_boston = LinearRegression()\nmlr_boston.fit(boston_data_input_train, boston_data_output_train)\n\n# Make predictions on the Boston Housing test set\nboston_predictions = mlr_boston.predict(boston_data_input_test)\n ",
      "outputs": []
    },
    {
      "id": "be14957d-4411-40e6-92e3-9a27b8dd7a61",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "10fc7dcb-17ed-4ba2-8a43-20302831e492"
        },
        "ExecuteTime": {
          "end_time": "2023-06-20T08:22:22.573795+00:00",
          "start_time": "2023-06-20T08:22:22.413271+00:00"
        }
      },
      "execution_count": null,
      "source": "import numpy as np\n\n# Define a function to calculate the Mean Absolute Percentage Error (MAPE)\ndef calculate_mape(y_true, y_pred):\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\n# Train an MLR model on the Boston Housing data\nmlr_boston = LinearRegression()\nmlr_boston.fit(boston_data_input_train, boston_data_output_train)\n\n# Make predictions on the Boston Housing test set\nboston_predictions = mlr_boston.predict(boston_data_input_test)\n\n# Calculate the MAPE for the Boston Housing predictions\nboston_mape = calculate_mape(boston_data_output_test, boston_predictions)\nprint('Boston Housing Data: MAPE =', boston_mape)",
      "outputs": []
    },
    {
      "id": "afef8737-0bbc-408c-8980-8c8310d36465",
      "cell_type": "code",
      "metadata": {
        "noteable": {
          "cell_type": "code",
          "output_collection_id": "98610195-739f-4946-ada8-557bdaf32ec4"
        },
        "ExecuteTime": {
          "end_time": "2023-06-20T08:09:51.865280+00:00",
          "start_time": "2023-06-20T08:09:50.990710+00:00"
        }
      },
      "execution_count": null,
      "source": "import matplotlib.pyplot as plt\n\n# Create a scatter plot for the Boston Housing data\nplt.figure(figsize=(10, 5))\nplt.scatter(boston_data_output_test, boston_predictions)\nplt.xlabel('Real Values')\nplt.ylabel('Predicted Values')\nplt.title('Boston Housing Data: Real vs Predicted Values')\nplt.grid(True)\nplt.show()",
      "outputs": []
    }
  ]
}